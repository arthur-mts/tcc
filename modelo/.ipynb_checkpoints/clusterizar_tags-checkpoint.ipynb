{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T00:02:12.221039369Z",
     "start_time": "2024-02-13T00:02:10.898780591Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pdfminer\n",
    "import time\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "\n",
    "import pytesseract\n",
    "import multiprocessing\n",
    "import swifter\n",
    "\n",
    "import urllib.request\n",
    "import nltk\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "\n",
    "import fasttext\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7cfc5582f28d317",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T00:02:12.269410077Z",
     "start_time": "2024-02-13T00:02:12.230213659Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "connection = sa.create_engine(\"postgresql://docker:docker@localhost/tcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e3d95bef2a67f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-13T00:02:13.946351939Z",
     "start_time": "2024-02-13T00:02:13.781549200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_keywords = pd.read_sql(sa.text(\n",
    "    \"\"\"\n",
    "select pk.keyword\n",
    "from tcc.proposicoes p\n",
    "left join tcc.proposicoes_keywords pk on p.id = pk.proposicao_id\n",
    "where p.tipo in ('PL', 'EMC', 'RDF', 'SBT') and pk is not null;\n",
    "\"\"\"\n",
    "), connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62958e395109237",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T23:54:46.050291565Z",
     "start_time": "2024-02-12T23:54:46.040320409Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_df_keywords_vectorized(df_keywords):\n",
    "    ## remove the 10% keywords that appears less\n",
    "    df_keywords = df_keywords[df_keywords.keyword.isin(df_keywords.keyword.value_counts().index[:int(len(df_keywords.keyword.value_counts())*0.9)])]\n",
    "    df_keywords = df_keywords.applymap(lambda x: re.sub(r\"\\(.*\\)\", \"\", x))\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    df_keywords = df_keywords.applymap(lambda x: \" \".join([word for word in x.split() if word not in stop_words]))\n",
    "    model = fasttext.load_model(\"/home/arthurs/Downloads/cc.pt.300.bin\")\n",
    "    df_keywords_unique = df_keywords.drop_duplicates()\n",
    "    df_keywords_unique[\"vectorized\"] = df_keywords_unique.swifter.apply(lambda x: model[x.keyword], axis=1)\n",
    "    ## store df_keywords_unique into a dataframe file that keeps the vectorized column\n",
    "    df_keywords_unique.to_pickle(\"df_keywords_unique.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d835dcf95b3ccb4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-12T23:55:42.114396979Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/arthurs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44914e044e64060ab7ce35378f50996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/9743 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13436/904812245.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_keywords_unique[\"vectorized\"] = df_keywords_unique.swifter.apply(lambda x: model[x.keyword], axis=1)\n"
     ]
    }
   ],
   "source": [
    "generate_df_keywords_vectorized(df_keywords)\n",
    "df_keywords_unique = pd.read_pickle(\"df_keywords_unique.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221031d469c776a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T23:52:18.555458301Z",
     "start_time": "2024-02-12T23:52:18.377230327Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>vectorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alteracao</td>\n",
       "      <td>[-0.0033493927, -0.005547726, 0.067980655, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>treinamento</td>\n",
       "      <td>[-0.026710147, 0.016000751, 0.020181265, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qualificacao</td>\n",
       "      <td>[5.3898857e-05, 0.026979893, 0.020165825, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agente transito</td>\n",
       "      <td>[-0.0055370205, 0.014777936, 0.027098073, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>criterio</td>\n",
       "      <td>[-0.105619274, 0.017132755, 0.059716024, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50605</th>\n",
       "      <td>visita intima _ lei crimes hediondos</td>\n",
       "      <td>[-0.009726655, 0.0042402777, -0.0013160722, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50607</th>\n",
       "      <td>feminicidio_ lei maria penha</td>\n",
       "      <td>[0.0077771586, -0.008991611, 0.024584565, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50610</th>\n",
       "      <td>medida protetiva urgencia_ codigo processo penal</td>\n",
       "      <td>[-0.0058593103, -0.004729941, 0.0040647383, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50622</th>\n",
       "      <td>proposta acordo</td>\n",
       "      <td>[0.015471814, -0.0068412395, 0.014883506, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50623</th>\n",
       "      <td>acordo nao persecucao civel</td>\n",
       "      <td>[-0.00957416, 0.0036707504, 0.00095402694, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9743 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                keyword  \\\n",
       "0                                             alteracao   \n",
       "2                                           treinamento   \n",
       "3                                          qualificacao   \n",
       "4                                       agente transito   \n",
       "5                                              criterio   \n",
       "...                                                 ...   \n",
       "50605              visita intima _ lei crimes hediondos   \n",
       "50607                      feminicidio_ lei maria penha   \n",
       "50610  medida protetiva urgencia_ codigo processo penal   \n",
       "50622                                   proposta acordo   \n",
       "50623                       acordo nao persecucao civel   \n",
       "\n",
       "                                              vectorized  \n",
       "0      [-0.0033493927, -0.005547726, 0.067980655, -0....  \n",
       "2      [-0.026710147, 0.016000751, 0.020181265, -0.04...  \n",
       "3      [5.3898857e-05, 0.026979893, 0.020165825, 0.00...  \n",
       "4      [-0.0055370205, 0.014777936, 0.027098073, 0.00...  \n",
       "5      [-0.105619274, 0.017132755, 0.059716024, -0.00...  \n",
       "...                                                  ...  \n",
       "50605  [-0.009726655, 0.0042402777, -0.0013160722, -0...  \n",
       "50607  [0.0077771586, -0.008991611, 0.024584565, -0.0...  \n",
       "50610  [-0.0058593103, -0.004729941, 0.0040647383, -0...  \n",
       "50622  [0.015471814, -0.0068412395, 0.014883506, -0.0...  \n",
       "50623  [-0.00957416, 0.0036707504, 0.00095402694, -0....  \n",
       "\n",
       "[9743 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keywords_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f1c984-ce21-4dee-944f-6c20328aba15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T23:49:35.115556632Z",
     "start_time": "2024-02-12T23:49:34.915753276Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = [np.array(matriz) for matriz in df_keywords_unique['vectorized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50c028f5083263",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Clusterização com KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7121d2-65b2-472e-bdf0-8752fb3b2c07",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-12T23:49:35.109999872Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m K:\n\u001B[1;32m     13\u001B[0m \t\u001B[38;5;66;03m# Building and fitting the model\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \tkmeanModel \u001B[38;5;241m=\u001B[39m KMeans(n_clusters\u001B[38;5;241m=\u001B[39mk)\n\u001B[0;32m---> 15\u001B[0m \t\u001B[43mkmeanModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m \tdistortions\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28msum\u001B[39m(np\u001B[38;5;241m.\u001B[39mmin(cdist(X_t, kmeanModel\u001B[38;5;241m.\u001B[39mcluster_centers_,\n\u001B[1;32m     18\u001B[0m \t\t\t\t\t\t\t\t\t\t\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meuclidean\u001B[39m\u001B[38;5;124m'\u001B[39m), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)) \u001B[38;5;241m/\u001B[39m df_keywords_unique[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvectorized\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     19\u001B[0m \tinertias\u001B[38;5;241m.\u001B[39mappend(kmeanModel\u001B[38;5;241m.\u001B[39minertia_)\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/sklearn/base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1150\u001B[0m     )\n\u001B[1;32m   1151\u001B[0m ):\n\u001B[0;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1519\u001B[0m, in \u001B[0;36mKMeans.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1515\u001B[0m best_inertia, best_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_init):\n\u001B[1;32m   1518\u001B[0m     \u001B[38;5;66;03m# Initialize centers\u001B[39;00m\n\u001B[0;32m-> 1519\u001B[0m     centers_init \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_centroids\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx_squared_norms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[43m        \u001B[49m\u001B[43minit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1523\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1524\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1525\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1526\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[1;32m   1527\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitialization complete\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1019\u001B[0m, in \u001B[0;36m_BaseKMeans._init_centroids\u001B[0;34m(self, X, x_squared_norms, init, random_state, sample_weight, init_size, n_centroids)\u001B[0m\n\u001B[1;32m   1016\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m sample_weight[init_indices]\n\u001B[1;32m   1018\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(init, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m init \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk-means++\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1019\u001B[0m     centers, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_kmeans_plusplus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1020\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1021\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_clusters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1022\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1023\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx_squared_norms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1024\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1025\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(init, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m init \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1027\u001B[0m     seeds \u001B[38;5;241m=\u001B[39m random_state\u001B[38;5;241m.\u001B[39mchoice(\n\u001B[1;32m   1028\u001B[0m         n_samples,\n\u001B[1;32m   1029\u001B[0m         size\u001B[38;5;241m=\u001B[39mn_clusters,\n\u001B[1;32m   1030\u001B[0m         replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1031\u001B[0m         p\u001B[38;5;241m=\u001B[39msample_weight \u001B[38;5;241m/\u001B[39m sample_weight\u001B[38;5;241m.\u001B[39msum(),\n\u001B[1;32m   1032\u001B[0m     )\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:255\u001B[0m, in \u001B[0;36m_kmeans_plusplus\u001B[0;34m(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)\u001B[0m\n\u001B[1;32m    252\u001B[0m np\u001B[38;5;241m.\u001B[39mclip(candidate_ids, \u001B[38;5;28;01mNone\u001B[39;00m, closest_dist_sq\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, out\u001B[38;5;241m=\u001B[39mcandidate_ids)\n\u001B[1;32m    254\u001B[0m \u001B[38;5;66;03m# Compute distances to center candidates\u001B[39;00m\n\u001B[0;32m--> 255\u001B[0m distance_to_candidates \u001B[38;5;241m=\u001B[39m \u001B[43m_euclidean_distances\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcandidate_ids\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_norm_squared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_squared_norms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msquared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    257\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;66;03m# update closest distances squared and potential for each candidate\u001B[39;00m\n\u001B[1;32m    260\u001B[0m np\u001B[38;5;241m.\u001B[39mminimum(closest_dist_sq, distance_to_candidates, out\u001B[38;5;241m=\u001B[39mdistance_to_candidates)\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:379\u001B[0m, in \u001B[0;36m_euclidean_distances\u001B[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001B[0m\n\u001B[1;32m    376\u001B[0m     distances \u001B[38;5;241m=\u001B[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001B[39;00m\n\u001B[0;32m--> 379\u001B[0m     distances \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[43msafe_sparse_dot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdense_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    380\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m XX\n\u001B[1;32m    381\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m YY\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/sklearn/utils/extmath.py:195\u001B[0m, in \u001B[0;36msafe_sparse_dot\u001B[0;34m(a, b, dense_output)\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    192\u001B[0m     ret \u001B[38;5;241m=\u001B[39m a \u001B[38;5;241m@\u001B[39m b\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m--> 195\u001B[0m     \u001B[43msparse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43missparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m sparse\u001B[38;5;241m.\u001B[39missparse(b)\n\u001B[1;32m    197\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m dense_output\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(ret, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoarray\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    199\u001B[0m ):\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39mtoarray()\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/scipy/sparse/_base.py:1461\u001B[0m, in \u001B[0;36missparse\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m   1456\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1458\u001B[0m sparray\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__doc__\u001B[39m \u001B[38;5;241m=\u001B[39m _spbase\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__doc__\u001B[39m\n\u001B[0;32m-> 1461\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21missparse\u001B[39m(x):\n\u001B[1;32m   1462\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Is `x` of a sparse array type?\u001B[39;00m\n\u001B[1;32m   1463\u001B[0m \n\u001B[1;32m   1464\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;124;03m    False\u001B[39;00m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   1487\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, _spbase)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "X_t = X\n",
    "K = range(1, 30)\n",
    "\n",
    "distortions = []\n",
    "inertias = []\n",
    "mapping1 = {}\n",
    "mapping2 = {}\n",
    "\n",
    "\n",
    "for k in K:\n",
    "\t# Building and fitting the model\n",
    "\tkmeanModel = KMeans(n_clusters=k)\n",
    "\tkmeanModel.fit(X_t)\n",
    "\n",
    "\tdistortions.append(sum(np.min(cdist(X_t, kmeanModel.cluster_centers_,\n",
    "\t\t\t\t\t\t\t\t\t\t'euclidean'), axis=1)) / df_keywords_unique[\"vectorized\"].shape[0])\n",
    "\tinertias.append(kmeanModel.inertia_)\n",
    "\n",
    "\tmapping1[k] = sum(np.min(cdist(X_t, kmeanModel.cluster_centers_,\n",
    "\t\t\t\t\t\t\t\t'euclidean'), axis=1)) / df_keywords_unique[\"vectorized\"].shape[0]\n",
    "\tmapping2[k] = kmeanModel.inertia_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f4104-7b8a-41ed-b362-e6acc4f76ca3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-12T23:49:35.136834945Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method using Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c797e83846e44ef9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-12T23:49:35.138363102Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "['direito peticao' 'direito acao' 'vitima _criacao' 'emissora televisao'\n",
      " 'unidade saude' 'clausula democratica' 'sujeicao' 'lei migracao'\n",
      " 'destinacao' '_composicao' 'governo federal alteracao'\n",
      " 'curso especializacao' 'fundamentacao' 'comercializacao'\n",
      " 'acao indenizacao' 'veiculacao' 'placenta _ alteracao' 'valoracao'\n",
      " 'adjudicacao' 'carta adjudicacao' 'interdicao' 'procedimento _alteracao'\n",
      " 'licenciamento ambiental _alteracao' 'patrimonio cultural _alteracao'\n",
      " 'medida protecao']\n",
      "\n",
      "\n",
      "Cluster 1\n",
      "['brasil' 'santos' 'parana' 'goias' 'radio' 'anapolis' 'indigena'\n",
      " 'rondonia' 'brasilia' 'araguari' 'paracatu' 'micareta' 'pracas'\n",
      " 'paraguai' 'amazonas' 'roraima' 'amapa' 'recife' 'pernambuco' 'marilia'\n",
      " 'ourinhos' 'capanema' 'tocantins' 'ceara' 'maranhao']\n",
      "\n",
      "\n",
      "Cluster 2\n",
      "['violencia sexual' 'casa noturna' 'clube social' 'saude animal'\n",
      " 'animal domestico' 'situacao risco' 'area lazer' 'obra publica'\n",
      " 'beneficio fiscal' 'porte arma' 'forcas armadas' 'policia civil'\n",
      " 'policia militar' 'guarda municipal' 'senado federal' 'policia penal'\n",
      " 'bebida alcoolica' 'codigo penal' 'monitor ensino' 'local privado'\n",
      " 'rodovia federal' 'sao paulo' 'exame medico' 'codigo civil'\n",
      " 'doenca grave']\n",
      "\n",
      "\n",
      "Cluster 3\n",
      "['administracao federal' 'empresa brasileira correios telegrafos'\n",
      " 'politica nacional longo prazo' 'politica publica'\n",
      " 'planejamento estrategico' 'desenvolvimento nacional'\n",
      " 'administracao publica' 'lei defesa concorrencia'\n",
      " 'infracao contra ordem economica' 'anticompetitividade'\n",
      " 'protocolo nao nao' 'estabelecimento comercial'\n",
      " 'selo nao nao - mulheres seguras' 'crime contra dignidade sexual'\n",
      " 'lei servico militar' 'alistamento militar _proibicao'\n",
      " 'certificado reservista' 'certificado dispensa incorporacao'\n",
      " 'emissora radiodifusao' 'estacao radio _criterio'\n",
      " 'defesa direitos animais'\n",
      " 'registro eletronico vacinacoes animais estimacao'\n",
      " 'lei diretrizes bases educacao nacional'\n",
      " 'alfabetizacao midiatica combate desinformacao' 'educacao midiatica']\n",
      "\n",
      "\n",
      "Cluster 4\n",
      "['criterio' 'exercicio' 'simbolo' 'veiculo' 'periodo' 'convenio'\n",
      " 'magisterio' 'calculo' 'beneficio' 'beneficiario' 'credito' 'imovel'\n",
      " 'bisavos' 'condomino' 'divorcio' 'advertencia' 'adocante' 'principios'\n",
      " 'proprietario' 'municipio' 'onibus' 'combustivel' 'inicio' 'matricula'\n",
      " 'petroleo']\n",
      "\n",
      "\n",
      "Cluster 5\n",
      "['equino' 'vacina' 'cancerologia' 'cancer' 'sintoma' 'gestante'\n",
      " 'parturiente' 'obesidade' 'triagem' 'medicamento' 'zoofilia'\n",
      " 'hormonioterapia' 'psoriase' 'fibromialgia' 'autista' 'tratamento'\n",
      " 'paciente' 'hospital' 'leucemia' 'gravidez' 'acometimento' 'diagnostico'\n",
      " 'trombofilia' 'anestesia' 'autismo']\n",
      "\n",
      "\n",
      "Cluster 6\n",
      "['mulher' 'pessoa' 'entrada' 'cama' 'creche' 'bebida' 'festa' 'usina'\n",
      " 'frota' 'parte' 'prova' 'escola' 'sede' 'motoneta' 'pesca' 'nova' 'vaga'\n",
      " 'rinha' 'vida' 'rua' 'vogal' 'favela' 'viagem' 'placa' 'fila']\n",
      "\n",
      "\n",
      "Cluster 7\n",
      "['janeiro' 'outubro' 'fevereiro' 'agosto' 'setembro' 'maio' 'junho'\n",
      " 'julho' 'abril' 'novembro' 'dia' 'dezembro' 'ano']\n",
      "\n",
      "\n",
      "Cluster 8\n",
      "['crianca' 'doenca' 'avos' 'acucar' 'sodio' 'prisao' 'cafe' 'berco'\n",
      " 'uniao' 'doacao' 'praca' 'saude' 'reu' 'preco' 'pensao' 'opcao' 'ameaca'\n",
      " 'grao' 'etica' 'aco' 'alcool' 'pecas' 'agua' 'oculos' 'sessao']\n",
      "\n",
      "\n",
      "Cluster 9\n",
      "['vitima' 'combate' 'atentado' 'acusado' 'atos' 'crime' 'feminicidio'\n",
      " 'criminoso' 'fascismo' 'nazismo' 'neonazismo' 'contra' 'maus-tratos'\n",
      " 'abandono' 'estupro' 'peculato' 'ferimento' 'abuso' 'tumulto' 'aborto'\n",
      " 'denuncia' 'afogamento' 'racismo' 'saque' 'sabotagem']\n",
      "\n",
      "\n",
      "Cluster 10\n",
      "['administracao direta' 'administracao indireta' 'atendimento vitima'\n",
      " 'perseguicao obsessiva' 'seguranca publica' 'vaga preferencial'\n",
      " 'assento preferencial' 'sociedade nacional'\n",
      " 'radiodifusao sonora frequencia modulada' 'homenagem postuma'\n",
      " 'educacao basica' 'noticia falsa' 'titulo honorifico' 'pessoa juridica'\n",
      " 'data comemorativa' 'pessoa fisica' 'policia judiciaria'\n",
      " 'substancia quimica' 'territorio nacional' 'corrupcao passiva'\n",
      " 'funcao administrativa' 'militar ativa' 'acesso irrestrito'\n",
      " 'teste bochechinha' 'fonte recursos']\n",
      "\n",
      "\n",
      "Cluster 11\n",
      "['idoso' 'conselheiro' 'pais' 'membro' 'agente' 'estrangeiro'\n",
      " 'contribuinte' 'indiciado' 'devedor' 'advogado' 'preso' 'professor'\n",
      " 'pedestre' 'mora' 'colaborador' 'vigilante' 'doador' 'homem' 'cargo'\n",
      " 'tutor' 'trabalhador' 'jovem' 'condenado' 'administrador' 'artista']\n",
      "\n",
      "\n",
      "Cluster 12\n",
      "['agente transito' 'servico postal' 'orgao publico' 'restaurante'\n",
      " 'atendimento preferencial' 'decreto-lei' 'estacao radio'\n",
      " 'atendimento veterinario' 'livro herois heroinas patria'\n",
      " 'jogador futebol' 'curriculo escolar' 'protocolo seguranca'\n",
      " 'operacao credito' 'ato atentatorio' 'estado democratico direito'\n",
      " 'acionista controlador' 'pais estrangeiro' 'estatuto desarmamento'\n",
      " 'policia federal' 'corpo bombeiros militar' 'policia legislativa'\n",
      " 'camara deputados' 'alucinogeno' 'prestador servico' 'aviso alerta']\n",
      "\n",
      "\n",
      "Cluster 13\n",
      "['maes']\n",
      "\n",
      "\n",
      "Cluster 14\n",
      "['treinamento' 'prioridade' 'diretrizes' 'finalidade' 'procedimento'\n",
      " 'garantia' 'direitos' 'facultatividade' 'cavalaria' 'pratica'\n",
      " 'envolvimento' 'respeito' 'recebimento' 'financiamento' 'internet'\n",
      " 'desaparecimento' 'autoridade' 'impedimento' 'democracia' 'recursos'\n",
      " 'metodologia' 'desnecessidade' 'contemporaneidade' 'reaparecimento'\n",
      " 'aposentadoria']\n",
      "\n",
      "\n",
      "Cluster 15\n",
      "['mae']\n",
      "\n",
      "\n",
      "Cluster 16\n",
      "['evento' 'hotel' 'nome' 'cadastro' 'contrato' 'telefone' 'transporte'\n",
      " 'alimento' 'programa' 'projeto' 'embargo' 'terceiro' 'julgamento'\n",
      " 'alimentador' 'registro' 'sigilo' 'lote' 'lazer' 'museu' 'teatro'\n",
      " 'estado' 'teclado' 'motor' 'fim' 'bancos']\n",
      "\n",
      "\n",
      "Cluster 17\n",
      "['gas']\n",
      "\n",
      "\n",
      "Cluster 18\n",
      "['re']\n",
      "\n",
      "\n",
      "Cluster 19\n",
      "['limite' 'pagamento' 'multa' 'prazo' 'despesa' 'consumo' 'perda' 'dados'\n",
      " 'parcela' 'desconto' 'provento' 'aluguel' 'custeio' 'aumento' 'bens'\n",
      " 'percentual' 'repasse' 'royalty' 'taxa' 'juros' 'falta' 'reajuste'\n",
      " 'carga' 'valor' 'posse']\n",
      "\n",
      "\n",
      "Cluster 20\n",
      "['bar' 'taxi' 'sangue' 'lixo' 'vidro' 'circo' 'gato' 'cavalo' 'leite'\n",
      " 'acre' 'cabo' 'cofre' 'canino' 'surdo' 'porto' 'ouro' 'rio' 'som' 'voo'\n",
      " 'sexo' 'arroz' 'touro' 'esgoto' 'chip' 'fumo']\n",
      "\n",
      "\n",
      "Cluster 21\n",
      "['alteracao' 'qualificacao' 'contratacao' 'criacao' 'protecao' 'prevencao'\n",
      " 'substituicao' 'sinalizacao' 'exigencia' 'proibicao' 'integracao'\n",
      " 'inscricao' 'inclusao' 'realizacao' 'ocupacao' 'alimentacao' 'divulgacao'\n",
      " 'isencao' 'aquisicao' 'tributacao' 'instituicao' 'transmissao'\n",
      " 'localizacao' 'autorizacao' 'condenacao']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Treinando o modelo com 22 clusters\n",
    "kmeanModel = KMeans(n_clusters=22)\n",
    "kmeanModel.fit(X)\n",
    "\n",
    "clusters = kmeanModel.predict(list(df_keywords_unique['vectorized']))\n",
    "\n",
    "cluster_words = [[] for i in range(22)]\n",
    "\n",
    "for i in range(22):\n",
    "    print(f\"Cluster {i}\")\n",
    "    words_in_cluster = df_keywords_unique.iloc[np.where(clusters == i)[0]].keyword.values\n",
    "    cluster_words[i] = words_in_cluster\n",
    "    print(words_in_cluster[:25])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550ebbf9ce6942e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T23:49:35.152655757Z",
     "start_time": "2024-02-12T23:49:35.138929197Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "clusters_inuteis = [8, 9, 15, 18, 19, 20, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b6ac8ae6ce30d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-12T23:49:35.139209252Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "clusters_words_uteis = []\n",
    "\n",
    "for i in range(len(cluster_words)):\n",
    "    if i not in clusters_inuteis:\n",
    "        clusters_words_uteis.append(cluster_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d4fda8268c28a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-12T23:49:35.140404038Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(clusters_words_uteis)):\n",
    "    print(f\"Cluster {i}\")\n",
    "    print(\", \".join(clusters_words_uteis[i][:30]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5978d00c83564",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-12T23:49:35.140654332Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "clusters = [\n",
    "    \"servicos publicos, legislacao e instituicoes governamentais.\",\n",
    "    \"direitos legais, processos judiciais e questoes legais.\",\n",
    "    \"procedimentos administrativos, eventos e contratos.\",\n",
    "    \"animais, substancias e elementos naturais.\",\n",
    "    \"saude, imoveis, alimentos e ambiente prisional.\",\n",
    "    \"problemas sociais, seguranca, educacao e saude publica.\",\n",
    "    \"grupos sociais, cidadaos e individuos diversos.\",\n",
    "    \"administracao publica, politicas governamentais e direitos dos cidadaos.\",\n",
    "    \"crimes, abusos, atos ilegais e violacoes.\",\n",
    "    \"despesas, obrigacoes financeiras e questoes financeiras.\",\n",
    "    \"prioridades, diretrizes, politicas e reformas.\",\n",
    "    \"infraestrutura urbana, transporte e locais publicos.\",\n",
    "    \"alteracoes, regulamentacoes, procedimentos e autorizacoes legais.\",\n",
    "    \"criterios, praticas, beneficios e obrigacoes.\",\n",
    "    \"localidades geograficas, cidades e estados brasileiros.\"\n",
    "]\n",
    "\n",
    "clusters_final = {}\n",
    "for i in range(len(clusters)):\n",
    "    clusters_final[clusters[i]] = clusters_words_uteis[i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62efc06017605161",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-12T23:49:35.140838359Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./clusters_final.json\", \"w\") as file:\n",
    "    json.dump(clusters_final, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb6be5b36359b5af",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-12T23:49:35.141014046Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## store kmeanModel into a file\n",
    "import pickle\n",
    "pickle.dump(kmeanModel, open(\"kmeanModel.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5afcd-3b2c-4974-8705-15df90b5ae95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
