{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:34.875018584Z",
     "start_time": "2024-02-08T02:24:34.524148584Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sqlalchemy as sa\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33513bd967b9ac33",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:34.968970139Z",
     "start_time": "2024-02-08T02:24:34.869246657Z"
    }
   },
   "outputs": [],
   "source": [
    "df_proposicoes = pd.read_csv(\"../scripts/df_proposicoes_treino.csv\")\n",
    "df_proposicoes = df_proposicoes.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd60115a957f0cb1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:35.184895280Z",
     "start_time": "2024-02-08T02:24:34.968959022Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/arthurs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('portuguese'))\n",
    "def limpar_keywords(keywords):\n",
    "    new_keywords = [re.sub(r\"\\(.*\\)\", \"\", x) for x in keywords]\n",
    "    new_keywords = [\" \".join([word for word in x.split() if word not in stop_words]) for x in new_keywords]\n",
    "    return new_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eef2e18c6803b26",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:35.266543529Z",
     "start_time": "2024-02-08T02:24:35.188306820Z"
    }
   },
   "outputs": [],
   "source": [
    "connection = sa.create_engine(\"postgresql://docker:docker@localhost/tcc\")\n",
    "df_keywords_por_proposicao = pd.read_sql(sa.text(\"\"\"\n",
    "select p.id, array_agg(pk.keyword) as keywords\n",
    "from tcc.proposicoes p\n",
    "join tcc.proposicoes_keywords pk on pk.proposicao_id = p.id\n",
    "group by p.id;\n",
    "\"\"\"),connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1882071387cc01da",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:36.234881695Z",
     "start_time": "2024-02-08T02:24:35.270526932Z"
    }
   },
   "outputs": [],
   "source": [
    "def extrair_keywords(row):\n",
    "    id = row[\"id_proposicao\"]\n",
    "    res = df_keywords_por_proposicao[df_keywords_por_proposicao[\"id\"] == id].keywords\n",
    "    if (len(res) == 0):\n",
    "        return []\n",
    "    keywords = res.iloc[0]\n",
    "    return limpar_keywords(keywords)\n",
    "\n",
    "df_proposicoes[\"keywords\"] = df_proposicoes.apply(extrair_keywords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2da1b724fb83c5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:36.235516883Z",
     "start_time": "2024-02-08T02:24:36.231255114Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./clusters_final.json\", \"r\") as f:\n",
    "    clusters = json.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6991eff3611ab06c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:36.243633612Z",
     "start_time": "2024-02-08T02:24:36.235925918Z"
    }
   },
   "outputs": [],
   "source": [
    "clusters_inverse = {}\n",
    "for key, value in clusters.items():\n",
    "    for word in value:\n",
    "        clusters_inverse[word] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e598525b77d051",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:36.265577216Z",
     "start_time": "2024-02-08T02:24:36.247876464Z"
    }
   },
   "outputs": [],
   "source": [
    "def encontrar_clusters(row):\n",
    "    current_clusters = set()\n",
    "    for keyword in row[\"keywords\"]:\n",
    "        if keyword in clusters_inverse:\n",
    "            current_clusters.add(clusters_inverse[keyword])\n",
    "    return list(current_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5bc78f4750a1ff7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:36.308287856Z",
     "start_time": "2024-02-08T02:24:36.267817265Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_10_keywords(keywords):\n",
    "    if len(keywords) <= 10:\n",
    "        return keywords\n",
    "    else:\n",
    "        return keywords[:10]\n",
    "\n",
    "## pegando 10 primeiras keywords de cada proposicao\n",
    "df_proposicoes = df_proposicoes.assign(keywords = df_proposicoes[\"keywords\"].apply(first_10_keywords))\n",
    "df_proposicoes = df_proposicoes.assign(proposicoes_clusters = df_proposicoes.apply(encontrar_clusters, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c45dbae4c8e07ce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Multi label classification"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "df_proposicoes_com_keywords = df_proposicoes[df_proposicoes[\"proposicoes_clusters\"].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "X = df_proposicoes_com_keywords[\"ementa_do_pdf_1pag_limpo\"]\n",
    "y = df_proposicoes_com_keywords[\"proposicoes_clusters\"]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_encoded = mlb.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_encoded, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:36.527071880Z",
     "start_time": "2024-02-08T02:24:36.305259465Z"
    }
   },
   "id": "63c71b191acccfa1",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "def exibir_metricas(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    # conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "    print(\"Precisão:\", precision)\n",
    "    print(\"Revocação:\", recall)\n",
    "    print(\"F1-Score:\", f1)\n",
    "    # print(\"Matriz de Confusão:\")\n",
    "    # print(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:36.538161174Z",
     "start_time": "2024-02-08T02:24:36.530597622Z"
    }
   },
   "id": "bc7136c102c764a6",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('MultiOutputClassifier+RandomForestClassifier',\n",
      "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])\n",
      "Precisão: 0.7442512619181155\n",
      "Revocação: 0.6836682122617208\n",
      "F1-Score: 0.7126745435016111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "multi_output_rfc = Pipeline([\n",
    "    ('MultiOutputClassifier+RandomForestClassifier', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "multi_output_gb = Pipeline([\n",
    "    ('MultiOutputClassifier+GradientBoostingClassifier', MultiOutputClassifier(GradientBoostingClassifier()))\n",
    "])\n",
    "\n",
    "classifier_chain_rfc = Pipeline([\n",
    "    ('ClassifierChain+RandomForestClassifier', ClassifierChain(RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "classifier_chain_gb = Pipeline([\n",
    "    ('ClassifierChain+GradientBoostingClassifier', ClassifierChain(GradientBoostingClassifier()))\n",
    "])\n",
    "\n",
    "models = [\n",
    "    multi_output_rfc,\n",
    "    # multi_output_gb,\n",
    "    # classifier_chain_rfc,\n",
    "    # classifier_chain_gb,\n",
    "] \n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    exibir_metricas(model, X_test, y_test)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:57.586004712Z",
     "start_time": "2024-02-08T02:24:36.534727290Z"
    }
   },
   "id": "4f6758ec403ff6e8",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def exibir_n_proposicoes_com_categorias(n, model):\n",
    "    df = df_proposicoes_com_keywords.sample(n)\n",
    "    X = df[\"ementa_do_pdf_1pag_limpo\"]\n",
    "    y = model.predict(tfidf_vectorizer.transform(X))\n",
    "    for i in range(n):\n",
    "        # print(\"Proposição:\", df.iloc[i][\"uri_documento\"])\n",
    "        # print(\"Categorias:\", mlb.inverse_transform(y[i].reshape(1, -1)))\n",
    "        print(X.iloc[i])\n",
    "        print(y[i])\n",
    "        print()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:57.586557537Z",
     "start_time": "2024-02-08T02:24:57.585904313Z"
    }
   },
   "id": "3a60aa7fb9b2bdaf",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee NR Art º Esta lei entra vigor primeiro dia ano seguinte Í publicação A N Art º Esta lei entra vigor primeiro dia ano seguinte É publicação Câmaa Desutados Avexo Gao nete CEP Bras aíDF ta Telefone cepicoo Qiamarna dagbr ES XXIV proventos aposentadoria inatividade reforma invalidez razão cargo integrantes carreiras policiais órgãos tratam º art inciso IV caput art ínciso XIll caput art incisos Vl art quardas municipais trata º art agentes trânsito trata inciso l º art todos Constituição Federal perícia oficial natureza criminal agentes segurança socioeducativos militares Forças Armadas O Congresso Nacional decreta Art º Esta Lei altera Lei nº dezembro conceder isenção imposto renda sobre proventos aposentadoria inatividade reforma invalidez razão cargo servidores militares atuam atividade defesa nacional segurança pública Art º O art º Lei nº dezembro passa vigorar seguinte redação\n",
      "[1 1 0 0 1 0 1 0 0 0 1 0 1 0 1]\n",
      "\n",
      "A oftamologia especialidade médica integra atenção ªí especializada Sistema UÚnico Saúde SUS média alta Éj complexidade sendo prestada âmbito ambulatorial hospitalar No entanto BT RA OFSSO JUSTIFICAÇÃO Art º Esta Lei entra vigor após decorridos noventa dias data publicação â º A assistência terapêutica integral trata alínea d inciso caput inclui atendimento oftalmológico âmbito atenção primária saúde NR Art º Art º O art º Lei nº setembro passa vigorar acrescido seguinte º O Congresso Nacional decreta Altera Lei nº setembro incluir campo atuação Sistema Único Saúde atendimento oftalmológico atenção primária saúde\n",
      "[1 1 0 0 0 0 1 0 0 0 1 1 1 0 1]\n",
      "\n",
      "Art º Esta Lei entra vigor data publicação ÉÉ ee NR z Art A distinção prestada mediante edição Lei decorridos dez anos morte presunção morte homenageado Art º O caput art º Lei nº novembro passa vigorar seguinte redação Art º Será inscrito Livro Heróis Pátria encontra Panteão Liberdade Democracia Brasília DF nome Mário Furtado O CONGRESSO NACIONAL decreta livro Heróis Pátria Inscreve nome Mário Furtado Do Sr Deputado Pr MARGO FELICIANO\n",
      "[1 1 0 0 0 0 0 1 0 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "exibir_n_proposicoes_com_categorias(3, multi_output_rfc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:57.632021933Z",
     "start_time": "2024-02-08T02:24:57.586048007Z"
    }
   },
   "id": "f9a8ba9d083b119a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 11\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Suponha que y_true e y_pred sejam seus rótulos verdadeiros e previsões\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Certifique-se de que ambos têm o formato correto (por exemplo, se forem codificados como one-hot)\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Se necessário, converta-os para rótulos de classe usando np.argmax()\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Calcula a matriz de confusão\u001B[39;00m\n\u001B[1;32m     10\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m multi_output_rfc\u001B[38;5;241m.\u001B[39mpredict(X_test)\n\u001B[0;32m---> 11\u001B[0m conf_matrix \u001B[38;5;241m=\u001B[39m \u001B[43mconfusion_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Define os rótulos das classes\u001B[39;00m\n\u001B[1;32m     14\u001B[0m classes \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClasse 1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClasse 2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClasse 16\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:214\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    210\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    211\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    212\u001B[0m         )\n\u001B[1;32m    213\u001B[0m     ):\n\u001B[0;32m--> 214\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    224\u001B[0m     )\n",
      "File \u001B[0;32m/usr/lib/python3.11/site-packages/sklearn/metrics/_classification.py:328\u001B[0m, in \u001B[0;36mconfusion_matrix\u001B[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001B[0m\n\u001B[1;32m    326\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m _check_targets(y_true, y_pred)\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 328\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is not supported\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m y_type)\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    331\u001B[0m     labels \u001B[38;5;241m=\u001B[39m unique_labels(y_true, y_pred)\n",
      "\u001B[0;31mValueError\u001B[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = multi_output_rfc.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "## TODO: pegar classes\n",
    "classes = [\"Classe 1\", \"Classe 2\", ..., \"Classe 16\"]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T02:24:58.126335998Z",
     "start_time": "2024-02-08T02:24:57.631831228Z"
    }
   },
   "id": "cbc2934ffbe64ab8",
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
